name: Performance Diff

on:
  pull_request:
    branches: [ main, master ]

jobs:
  performance-diff:
    runs-on: ubuntu-latest
    
    permissions:
      pull-requests: write
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: '8.0.x'
    
    - name: Install required tools
      run: |
        sudo apt-get update
        sudo apt-get install -y bc
    
    - name: Restore dependencies
      run: dotnet restore
    
    # Build and benchmark current branch (PR)
    - name: Build and benchmark current branch
      run: |
        echo "Building PR branch..."
        dotnet build --configuration Release --no-restore
        echo "Running benchmarks..."
        dotnet run --project src/HashStamp.Benchmarks/HashStamp.Benchmarks.csproj --configuration Release --no-build -- --quick 2>&1 | tee pr_benchmark.txt
    
    - name: Collect PR benchmark results
      run: |
        # Extract key benchmark metrics from summary table for PR
        echo "Extracting PR benchmark data..."
        # Look for the summary table and extract the three benchmark methods (only table rows starting with |)
        grep -A 10 "| Method" pr_benchmark.txt | grep -E "CompileTimeHashAccess|RuntimeHashAccess|CountAllMethods" | grep -E "^\|" > pr_results.txt || echo "No benchmark results found" > pr_results.txt
        echo "PR results:"
        cat pr_results.txt
    
    # Checkout base branch and build for comparison
    - name: Checkout base branch
      run: |
        git checkout ${{ github.event.pull_request.base.sha }}
        dotnet restore
    
    - name: Build and benchmark base branch
      run: |
        echo "Building base branch..."
        dotnet build --configuration Release --no-restore
        echo "Running benchmarks..."
        dotnet run --project src/HashStamp.Benchmarks/HashStamp.Benchmarks.csproj --configuration Release --no-build -- --quick 2>&1 | tee base_benchmark.txt
    
    - name: Collect base benchmark results and generate comparison
      run: |
        # Extract key benchmark metrics from summary table for base
        echo "Extracting base benchmark data..."
        grep -A 10 "| Method" base_benchmark.txt | grep -E "CompileTimeHashAccess|RuntimeHashAccess|CountAllMethods" | grep -E "^\|" > base_results.txt || echo "No benchmark results found" > base_results.txt
        echo "Base results:"
        cat base_results.txt
        
        # Create concise performance comparison report
        echo "## Performance Comparison" > performance_report.md
        echo "" >> performance_report.md
        echo "| Benchmark | Original | Optimized | Change |" >> performance_report.md
        echo "|-----------|----------|-----------|--------|" >> performance_report.md
        
        # Function to extract mean time and calculate percentage change
        calculate_comparison() {
          local method_name="$1"
          local pr_line=$(grep "$method_name" pr_results.txt | head -1)
          local base_line=$(grep "$method_name" base_results.txt | head -1)
          
          echo "Comparing $method_name:"
          echo "  PR line: $pr_line"
          echo "  Base line: $base_line"
          
          if [[ -n "$pr_line" && -n "$base_line" ]]; then
            # Extract mean values from summary table (2nd column after method name)
            # Format: | CompileTimeHashAccess |  4.045 us | ...
            pr_mean=$(echo "$pr_line" | awk -F'|' '{print $3}' | xargs)
            base_mean=$(echo "$base_line" | awk -F'|' '{print $3}' | xargs)
            
            echo "  Extracted - PR: '$pr_mean', Base: '$base_mean'"
            
            if [[ -n "$pr_mean" && -n "$base_mean" && "$pr_mean" != "No benchmark results found" && "$base_mean" != "No benchmark results found" ]]; then
              # Calculate percentage change
              pr_value=$(echo "$pr_mean" | grep -oE '[0-9]+\.?[0-9]*')
              base_value=$(echo "$base_mean" | grep -oE '[0-9]+\.?[0-9]*')
              
              if [[ -n "$pr_value" && -n "$base_value" ]]; then
                change=$(echo "scale=2; (($pr_value - $base_value) / $base_value) * 100" | bc -l 2>/dev/null || echo "N/A")
                if [[ "$change" != "N/A" ]]; then
                  if (( $(echo "$change > 0" | bc -l) )); then
                    change_text="+${change}% slower"
                  elif (( $(echo "$change < 0" | bc -l) )); then
                    change_text="${change}% faster"  
                  else
                    change_text="No change"
                  fi
                else
                  change_text="Unable to calculate"
                fi
                echo "| $method_name | $base_mean | $pr_mean | $change_text |" >> performance_report.md
              else
                echo "| $method_name | $base_mean | $pr_mean | Unable to compare |" >> performance_report.md
              fi
            else
              echo "| $method_name | Data unavailable | Data unavailable | Unable to compare |" >> performance_report.md
            fi
          else
            echo "| $method_name | No data | No data | No comparison possible |" >> performance_report.md
          fi
        }
        
        # Generate comparison for key methods
        calculate_comparison "CompileTimeHashAccess"
        calculate_comparison "RuntimeHashAccess" 
        calculate_comparison "CountAllMethods"
        
        echo "" >> performance_report.md
        echo "*Performance impact shows the change from original to optimized code.*" >> performance_report.md
        
        echo "Final performance report:"
        cat performance_report.md
    
    - name: Comment PR
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('performance_report.md', 'utf8');
          
          // Find existing performance comments
          const comments = await github.rest.issues.listComments({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
          });
          
          const perfComments = comments.data.filter(comment => 
            comment.body.includes('⚡ Performance Benchmark Results')
          );
          
          const commentBody = `## ⚡ Performance Benchmark Results\n\n${report}`;
          
          if (perfComments.length > 0) {
            // Update the first existing performance comment
            console.log(`Updating existing performance comment ${perfComments[0].id}`);
            await github.rest.issues.updateComment({
              comment_id: perfComments[0].id,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: commentBody
            });
            
            // Delete any additional performance comments to avoid duplicates
            for (let i = 1; i < perfComments.length; i++) {
              console.log(`Deleting duplicate performance comment ${perfComments[i].id}`);
              await github.rest.issues.deleteComment({
                comment_id: perfComments[i].id,
                owner: context.repo.owner,
                repo: context.repo.repo,
              });
            }
          } else {
            // Create new performance comment if none exists
            console.log('Creating new performance comment');
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: commentBody
            });
          }