name: Performance Diff

on:
  pull_request:
    branches: [ main, master ]

jobs:
  performance-diff:
    runs-on: ubuntu-latest
    
    permissions:
      pull-requests: write
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: '8.0.x'
    
    - name: Install required tools
      run: |
        sudo apt-get update
        sudo apt-get install -y bc
    
    - name: Restore dependencies
      run: dotnet restore
    
    # Build and benchmark current branch (PR)
    - name: Build and benchmark current branch
      run: |
        echo "Building PR branch..."
        dotnet build --configuration Release --no-restore
        echo "Running benchmarks..."
        dotnet run --project src/HashStamp.Benchmarks/HashStamp.Benchmarks.csproj --configuration Release --no-build -- --quick
    
    - name: Collect PR benchmark results
      run: |
        # Extract key benchmark metrics from JSON file for PR
        echo "Extracting PR benchmark data from JSON..."
        if [ -f "BenchmarkDotNet.Artifacts/results/HashStamp.Benchmarks.QuickBenchmarks-report-brief.json" ]; then
          cp BenchmarkDotNet.Artifacts/results/HashStamp.Benchmarks.QuickBenchmarks-report-brief.json pr_results.json
          echo "PR JSON results saved"
          ls -la pr_results.json
        else
          echo "JSON file not found"
          find . -name "*.json" -type f
        fi
    
    # Checkout base branch and build for comparison
    - name: Checkout base branch
      run: |
        git checkout ${{ github.event.pull_request.base.sha }}
        dotnet restore
    
    - name: Build and benchmark base branch
      run: |
        echo "Building base branch..."
        dotnet build --configuration Release --no-restore
        echo "Running benchmarks..."
        dotnet run --project src/HashStamp.Benchmarks/HashStamp.Benchmarks.csproj --configuration Release --no-build -- --quick
    
    - name: Collect base benchmark results and generate comparison
      run: |
        # Extract key benchmark metrics from JSON file for base
        echo "Extracting base benchmark data from JSON..."
        if [ -f "BenchmarkDotNet.Artifacts/results/HashStamp.Benchmarks.QuickBenchmarks-report-brief.json" ]; then
          cp BenchmarkDotNet.Artifacts/results/HashStamp.Benchmarks.QuickBenchmarks-report-brief.json base_results.json
          echo "Base JSON results saved"
          ls -la base_results.json
        else
          echo "Base JSON file not found"
          find . -name "*.json" -type f
        fi
        
        # Install jq for JSON parsing
        if ! command -v jq &> /dev/null; then
          echo "Installing jq..."
          sudo apt-get update && sudo apt-get install -y jq
        fi
        
        # Create concise performance comparison report using JSON data
        echo "## Performance Comparison" > performance_report.md
        echo "" >> performance_report.md
        echo "| Benchmark | Original (μs) | Optimized (μs) | Change |" >> performance_report.md
        echo "|-----------|---------------|----------------|--------|" >> performance_report.md
        
        # Function to extract mean time from JSON and calculate percentage change
        calculate_comparison() {
          local method_name="$1"
          
          echo "Comparing $method_name..."
          
          # Extract mean values from JSON (in nanoseconds, convert to microseconds)
          if [ -f "pr_results.json" ] && [ -f "base_results.json" ]; then
            pr_mean_ns=$(jq -r ".Benchmarks[] | select(.Method == \"$method_name\") | .Statistics.Mean" pr_results.json 2>/dev/null)
            base_mean_ns=$(jq -r ".Benchmarks[] | select(.Method == \"$method_name\") | .Statistics.Mean" base_results.json 2>/dev/null)
            
            echo "  Extracted - PR: '$pr_mean_ns' ns, Base: '$base_mean_ns' ns"
            
            if [[ "$pr_mean_ns" != "null" && "$base_mean_ns" != "null" && -n "$pr_mean_ns" && -n "$base_mean_ns" ]]; then
              # Convert nanoseconds to microseconds for better readability
              pr_mean_us=$(echo "scale=3; $pr_mean_ns / 1000" | bc -l)
              base_mean_us=$(echo "scale=3; $base_mean_ns / 1000" | bc -l)
              
              # Calculate percentage change
              change=$(echo "scale=2; (($pr_mean_ns - $base_mean_ns) / $base_mean_ns) * 100" | bc -l 2>/dev/null || echo "N/A")
              if [[ "$change" != "N/A" ]]; then
                if (( $(echo "$change > 0" | bc -l) )); then
                  change_text="+${change}% slower"
                elif (( $(echo "$change < 0" | bc -l) )); then
                  change_text="${change}% faster"  
                else
                  change_text="No change"
                fi
              else
                change_text="Unable to calculate"
              fi
              echo "| $method_name | ${base_mean_us} | ${pr_mean_us} | $change_text |" >> performance_report.md
            else
              echo "| $method_name | Data unavailable | Data unavailable | Unable to compare |" >> performance_report.md
            fi
          else
            echo "| $method_name | No data | No data | No comparison possible |" >> performance_report.md
          fi
        }
        
        # Generate comparison for key methods
        calculate_comparison "CompileTimeHashAccess"
        calculate_comparison "RuntimeHashAccess" 
        calculate_comparison "CountAllMethods"
        
        echo "" >> performance_report.md
        echo "*Performance values are shown in microseconds (μs). Negative change % indicates better performance.*" >> performance_report.md
        
        echo "Final performance report:"
        cat performance_report.md
    
    - name: Comment PR and Update Description
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('performance_report.md', 'utf8');
          
          // Find existing performance comments
          const comments = await github.rest.issues.listComments({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
          });
          
          const perfComments = comments.data.filter(comment => 
            comment.body.includes('⚡ Performance Benchmark Results')
          );
          
          const commentBody = `<details>\n<summary>⚡ Performance Benchmark Results</summary>\n\n${report}\n\n</details>`;
          
          if (perfComments.length > 0) {
            // Update the first existing performance comment
            console.log(`Updating existing performance comment ${perfComments[0].id}`);
            await github.rest.issues.updateComment({
              comment_id: perfComments[0].id,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: commentBody
            });
            
            // Delete any additional performance comments to avoid duplicates
            for (let i = 1; i < perfComments.length; i++) {
              console.log(`Deleting duplicate performance comment ${perfComments[i].id}`);
              await github.rest.issues.deleteComment({
                comment_id: perfComments[i].id,
                owner: context.repo.owner,
                repo: context.repo.repo,
              });
            }
          } else {
            // Create new performance comment if none exists
            console.log('Creating new performance comment');
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: commentBody
            });
          }

          // Update PR description with performance report
          console.log('Updating PR description with performance report');
          
          // Get current PR details
          const pr = await github.rest.pulls.get({
            owner: context.repo.owner,
            repo: context.repo.repo,
            pull_number: context.issue.number
          });
          
          let currentBody = pr.data.body || '';
          
          // Remove any existing performance report section from PR description
          const performanceSection = /\n\n<details>\s*<summary>⚡ Performance Benchmark Results<\/summary>[\s\S]*?<\/details>/g;
          currentBody = currentBody.replace(performanceSection, '');
          
          // Create collapsible performance section for PR description
          const collapsiblePerformanceSection = `\n\n<details>\n<summary>⚡ Performance Benchmark Results</summary>\n\n${report}\n\n</details>`;
          
          // Add performance section to the end of PR description
          const updatedBody = currentBody + collapsiblePerformanceSection;
          
          // Update the PR description
          await github.rest.pulls.update({
            owner: context.repo.owner,
            repo: context.repo.repo,
            pull_number: context.issue.number,
            body: updatedBody
          });
          
          console.log('PR description updated with performance report');